{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.agentchat.contrib.agent_builder import AgentBuilder\n",
    "\n",
    "config_file = \"./config.json\"\n",
    "default_llm_config = {\n",
    "    'temperature': 0\n",
    "}\n",
    "builder = AgentBuilder(config_file_or_env=config_file, builder_model='gpt-4-test', agent_model='gpt-4-test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_task = \"Find a paper on arxiv by programming, and analyze its application in some domain. For example, find a latest paper about gpt-4 on arxiv and find its potential applications in software.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m==> Generating agents...\u001b[0m\n",
      "['Data_Analysis_Expert', 'AI_Expert', 'Computer_Science_Expert', 'Software_Development_Expert', 'Research_Analysis_Expert'] are generated.\n",
      "\u001b[32m==> Generating system message...\u001b[0m\n",
      "Preparing system message for Data_Analysis_Expert\n",
      "Preparing system message for AI_Expert\n",
      "Preparing system message for Computer_Science_Expert\n",
      "Preparing system message for Software_Development_Expert\n",
      "Preparing system message for Research_Analysis_Expert\n",
      "\u001b[32m==> Generating description...\u001b[0m\n",
      "Preparing description for Data_Analysis_Expert\n",
      "Preparing description for AI_Expert\n",
      "Preparing description for Computer_Science_Expert\n",
      "Preparing description for Software_Development_Expert\n",
      "Preparing description for Research_Analysis_Expert\n",
      "\u001b[32m==> Creating agents...\u001b[0m\n",
      "Creating agent Data_Analysis_Expert...\n",
      "Creating agent AI_Expert...\n",
      "Creating agent Computer_Science_Expert...\n",
      "Creating agent Software_Development_Expert...\n",
      "Creating agent Research_Analysis_Expert...\n",
      "Adding user console proxy...\n"
     ]
    }
   ],
   "source": [
    "# build\n",
    "agent_list, agent_configs = builder.build(building_task, default_llm_config, coding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mData_Analysis_Expert\u001b[0m (to chat_manager):\n",
      "\n",
      "Find a recent paper about gpt-4 on arxiv and find its potential applications in software.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Research_Analysis_Expert\n",
      "\u001b[0m\n",
      "\u001b[33mResearch_Analysis_Expert\u001b[0m (to chat_manager):\n",
      "\n",
      "Sure, I will start by searching for recent papers on GPT-4 in the arXiv open archive. I will focus on those that have potential applications in software development. Let's use the arXiv API for this task. \n",
      "\n",
      "We can use the 'search_query' parameter to filter the results. In this case, we will set it to 'all:gpt-4' to search for all papers that mention GPT-4. We will also sort the results by 'submittedDate' to get the most recent papers first. \n",
      "\n",
      "Let's proceed with this.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Computer_terminal\n",
      "\u001b[0m\n",
      "\u001b[33mComputer_terminal\u001b[0m (to chat_manager):\n",
      "\n",
      "There is no code from the last 1 message for me to execute. Group chat manager should let other participants to continue the conversation. If the group chat manager want to end the conversation, you should let other participant reply me only with \"TERMINATE\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Computer_Science_Expert\n",
      "\u001b[0m\n",
      "\u001b[33mComputer_Science_Expert\u001b[0m (to chat_manager):\n",
      "\n",
      "Sure, let's use the arXiv API to find the most recent papers on GPT-4. We can use the 'search_query' parameter to filter the results. In this case, we will set it to 'all:gpt-4' to search for all papers that mention GPT-4. We will also sort the results by 'submittedDate' to get the most recent papers first. \n",
      "\n",
      "Here is the Python code to do this.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Computer_terminal\n",
      "\u001b[0m\n",
      "\u001b[33mComputer_terminal\u001b[0m (to chat_manager):\n",
      "\n",
      "There is no code from the last 1 message for me to execute. Group chat manager should let other participants to continue the conversation. If the group chat manager want to end the conversation, you should let other participant reply me only with \"TERMINATE\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Software_Development_Expert\n",
      "\u001b[0m\n",
      "\u001b[33mSoftware_Development_Expert\u001b[0m (to chat_manager):\n",
      "\n",
      "I apologize for the confusion. Here is the Python code to fetch the most recent papers on GPT-4 from arXiv using its API. We will use the 'requests' and 'feedparser' libraries to send a GET request to the API and parse the returned RSS feed, respectively. \n",
      "\n",
      "```python\n",
      "import requests\n",
      "import feedparser\n",
      "\n",
      "# Define the base URL for the arXiv API\n",
      "base_url = 'http://export.arxiv.org/api/query?'\n",
      "\n",
      "# Define the search parameters\n",
      "search_params = 'search_query=all:gpt-4&start=0&max_results=1&sortBy=submittedDate&sortOrder=descending'\n",
      "\n",
      "# Send a GET request to the arXiv API\n",
      "response = requests.get(base_url + search_params)\n",
      "\n",
      "# Parse the returned RSS feed\n",
      "feed = feedparser.parse(response.content)\n",
      "\n",
      "# Print the title and summary of the most recent paper\n",
      "print(\"Title: \", feed.entries[0].title)\n",
      "print(\"Summary: \", feed.entries[0].summary)\n",
      "```\n",
      "\n",
      "Please install the necessary libraries and run the code.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Computer_terminal\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33mComputer_terminal\u001b[0m (to chat_manager):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: \n",
      "Traceback (most recent call last):\n",
      "  File \"\", line 2, in <module>\n",
      "    import feedparser\n",
      "ModuleNotFoundError: No module named 'feedparser'\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Software_Development_Expert\n",
      "\u001b[0m\n",
      "\u001b[33mSoftware_Development_Expert\u001b[0m (to chat_manager):\n",
      "\n",
      "It seems like the 'feedparser' module is not installed. We need to install it before we can proceed. Here is the command to install 'feedparser':\n",
      "\n",
      "```sh\n",
      "pip install feedparser\n",
      "```\n",
      "\n",
      "After installing 'feedparser', please run the previous Python code again.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Computer_terminal\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is sh)...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\Anaconda3\\envs\\island\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\ProgramData\\Anaconda3\\envs\\island\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\envs\\island\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\envs\\island\\lib\\subprocess.py\", line 1515, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "  File \"c:\\ProgramData\\Anaconda3\\envs\\island\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xcb in position 169: invalid continuation byte\n",
      "Exception in thread Thread-9 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\Anaconda3\\envs\\island\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\ProgramData\\Anaconda3\\envs\\island\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\envs\\island\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\envs\\island\\lib\\subprocess.py\", line 1515, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "  File \"c:\\ProgramData\\Anaconda3\\envs\\island\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xcb in position 169: invalid continuation byte\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mComputer_terminal\u001b[0m (to chat_manager):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Collecting feedparser\n",
      "  Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "     ---------------------------------------- 0.0/81.3 kB ? eta -:--:--\n",
      "     --------------- ------------------------ 30.7/81.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 81.3/81.3 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting sgmllib3k\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: sgmllib3k\n",
      "  Building wheel for sgmllib3k (setup.py): started\n",
      "  Building wheel for sgmllib3k (setup.py): finished with status 'done'\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6048 sha256=2f7d03d94fb8745ed5172043075b787bc83c6d47c69a9980ddc0817d86706136\n",
      "  Stored in directory: c:\\users\\yui\\appdata\\local\\pip\\cache\\wheels\\65\\7a\\a7\\78c287f64e401255dff4c13fdbc672fed5efbfd21c530114e1\n",
      "Successfully built sgmllib3k\n",
      "Installing collected packages: sgmllib3k, feedparser\n",
      "Successfully installed feedparser-6.0.11 sgmllib3k-1.0.0\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Computer_terminal\n",
      "\u001b[0m\n",
      "\u001b[33mComputer_terminal\u001b[0m (to chat_manager):\n",
      "\n",
      "There is no code from the last 1 message for me to execute. Group chat manager should let other participants to continue the conversation. If the group chat manager want to end the conversation, you should let other participant reply me only with \"TERMINATE\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Software_Development_Expert\n",
      "\u001b[0m\n",
      "\u001b[33mSoftware_Development_Expert\u001b[0m (to chat_manager):\n",
      "\n",
      "Now that we have installed the 'feedparser' module, let's run the previous Python code again to fetch the most recent papers on GPT-4 from arXiv.\n",
      "\n",
      "```python\n",
      "import requests\n",
      "import feedparser\n",
      "\n",
      "# Define the base URL for the arXiv API\n",
      "base_url = 'http://export.arxiv.org/api/query?'\n",
      "\n",
      "# Define the search parameters\n",
      "search_params = 'search_query=all:gpt-4&start=0&max_results=1&sortBy=submittedDate&sortOrder=descending'\n",
      "\n",
      "# Send a GET request to the arXiv API\n",
      "response = requests.get(base_url + search_params)\n",
      "\n",
      "# Parse the returned RSS feed\n",
      "feed = feedparser.parse(response.content)\n",
      "\n",
      "# Print the title and summary of the most recent paper\n",
      "print(\"Title: \", feed.entries[0].title)\n",
      "print(\"Summary: \", feed.entries[0].summary)\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Computer_terminal\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33mComputer_terminal\u001b[0m (to chat_manager):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: \n",
      "Traceback (most recent call last):\n",
      "  File \"\", line 2, in <module>\n",
      "    import feedparser\n",
      "ModuleNotFoundError: No module named 'feedparser'\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import autogen\n",
    "\n",
    "def start_task(execution_task: str, agent_list: list, llm_config: dict):\n",
    "    config_list = autogen.config_list_from_json(config_file, filter_dict={\"model\": [\"gpt-4-test\"]})\n",
    "\n",
    "    group_chat = autogen.GroupChat(agents=agent_list, messages=[], max_round=12)\n",
    "    manager = autogen.GroupChatManager(\n",
    "        groupchat=group_chat, llm_config={\"config_list\": config_list, **llm_config}\n",
    "    )\n",
    "    agent_list[0].initiate_chat(manager, message=execution_task)\n",
    "\n",
    "start_task(\n",
    "    execution_task=\"Find a recent paper about gpt-4 on arxiv and find its potential applications in software.\",\n",
    "    agent_list=agent_list,\n",
    "    llm_config=default_llm_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean\n",
    "# builder.clear_all_agents(recycle_endpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mBuilding config saved to ./save_agentbuild_config.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# save\n",
    "saved_path = builder.save(\"./save_agentbuild_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "new_builder = AgentBuilder(config_file_or_env=config_file, builder_model='gpt-4-test', agent_model='gpt-4-test')\n",
    "agent_list, agent_config = new_builder.load(saved_path)\n",
    "# skip build\n",
    "start_task(\n",
    "    execution_task=\"Find a recent paper about gpt-4 on arxiv and find its potential applications in software.\",\n",
    "    agent_list=agent_list,\n",
    "    llm_config=default_llm_config\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "island",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
